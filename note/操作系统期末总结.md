单道批处理系统的特征：
自动型，顺序性，单道性
多道批处理系统的出现为了更加充分提高资源利用率和系统吞吐量
在该系统中，用户提交的所有作业都先放在外存并排成一个队列，称为“后备队列”
然后，由作业调度程序按一定的的算法从后备队列中讲若干个当进程调入到内存。使他们共享CPU和
系统中的各种资源。具体地说，在OS中，引入多道程序设计技术：
提高了CPU的利用率
提高了内存和IO设备的利用率
提高系统吞吐量

多道批处理系统的优缺点：
资源利用率高
系统吞吐量大
平均周转时间长
无交互能力

多道批处理系统需要解决的问题：
处理剂管理问题
内存管理问题
IO设备管理问题
作业管理问题

应在计算机系统中增加一组软件：用以对上述问题进行妥善有效处理。这组软件应包括：
能控制和管理四大资源的软件，合理对各类资源进行调度的软件，以及方便用户使用计算机
的软件，正是这样一组软件构成了操作系统。
操作系统是一组控制和管理计算机软件和硬件资源，合理对各类作业进行调度，以及方便用户
使用后的程序集合

分时系统
及时几首用户指令，及时处理，在多个用户同时在使用同一主机的情况下，也能做到有应必答
特征：多路性，独立性，及时性，交互性

实时系统：多了个可靠性，相比于分时系统

操作系统的发展
单用户单任务－－》单用户多任务－－－》多用户多任务

操作系统的基本特征：并发和并行
- 引入进程
- 引入线程

共享性
- 在操作系统的环境下，所谓共享，指系统中的资源可供内存中多个并发执行的进程共同使用
相应的，把这种资源共同使用称为资源共享，或者称为资源复用
- 进程对资源的共享有以下两种：
互斥共享
同时访问

虚拟技术
时分复用，就是分时使用方式
- 虚拟处理机技术
- 虚拟设备技术
- 空分复用技术
虚拟磁盘技术
虚拟存储器技术

异步性

操作系统的主要功能
处理机管理功能
- 进程控制
- 进程同步
- 进程通信
- 调度（作业调度，进程调度）

存储管理功能
- 内存分配
- 内存保护
- 地址映射
- 内存扩充

设备管理功能
- 缓冲管理
- 设备分配
- 设备处理

文件管理功能
- 文件存储空间的管理
- 目录管理
- 文件读写管理和保护

操作系统与用户之间的接口
- 用户接口
- 程序接口

程序顺秀执行的特征：
顺序性：按照程序结构所指定的次序
封闭性：独占全部资源，计算机的状态只由于该程序的控制逻辑决定
可在现性：初始结果相同，则结果相同

程序的并发执行的特征：间断性，不可再现性，失去封闭性

进程的特征：结构特征，通常程序是不能并发执行的，为使程序能独立运行，应为之
配置进程控制块，PCB，而由程序段、相关的数据段和PCB三部分便构成了进程实体
撤销进程就是撤销进程中的PCB
动态性，进程的实质是进程实体的一次执行过程，动态性是进程的最基本特征
并发性，这是指进程实体同存于内存中，并且能在同一时间内同时运行。并发性是进程
的重要特征也是OS的重要特征

独立性
异步型
进程按照按各自独立不可预知的速度向前推进，或说进程实体按异步方式运行
进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位

进程最基本的状态的转换：活动－－》就绪－－》阻塞

挂起状态
引入挂起状态的原因：
终端用户的请求
父进程请求
负荷调节的需要
操作系统的需要

进程状态的转化：

PCB中的主要信息：
进程表示符信息
进程状态信息
控制信息
调度信息

进程控制块的组织方式：
链接方式，索引方式

引起创建进程的事件：
用户登录
作业调度
提供服务
应用请求

进程的创建：
申请进程控制块
为新进程分配资源
初始化进程控制块
将新进程插入到就绪队列

进程的终止过程：
获取PCB，独处进程的状态
若被终止进程正处于执行状态，应立即终止该进程的执行，并设置调度标志，
用于指示该进程被终止后应进行的调度
若该进程还有子孙进程，还应将所有子孙进程予以终止，以防他们成为不可控的进程
若将终止进程所拥有的全部资源，或者归还给父进程，或者归还给系统
若将终止进程从所在队列中移出，等待其他程序来搜集信息

进程的激活过程：
系统利用激活原语active将指定进程激活，激活原语先将进程从外存调入到内存，检查该进程的现行状态，
若是静止就绪，则将其改成活动就绪，若是静止阻塞，则将其改成活动阻塞。要是采用抢占调度策略，则每当新进程
进入就绪队列时，应检查是否进行重新调度，即由调度程序将激活进程与当前进程进行优先级的比较，如果激活进程
的优先级更低，则不必重新调度，否则剥夺当前进程的运行，把处理机分配给刚被激活的进程

进程同步的概念：
- 两种相互制约的关系
间接相互制约：同处于一个系统的进程，通常都共享某种系统资源。
直接相互制约：这种制约源于进程之间的合作。

- 临界资源

临界区：多个进程必须互斥地对临界区进行访问
每个进程中访问临界资源的那段代码称为临界区

同步机制应遵循的规则：

空闲让进
忙则等待
有限等待
让权等待

信号量机制
- 整数型信号量：
wait(S) :  while(S<0) do no-op
           S=S-1
signal(S) : S=S+1
wait(S)和signal(S)是两个原子操作，因此，他们在执行时是不可中断的。

- 记录型信号量

在整型信号量机制中的wait操作，只要是信号量S<=0，就会不断地测试，因此，该机制并未遵循
让权等待准则，而是使进程处于忙等状态。记录型信号量则是一种不存在忙等现象的进程同步机制

代表共享资源的数据结构，以及对该共享数据结构实施
的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块，
我们称之为管程。
管程被请求和释放资源的进程所调用

and型信号量：
当某进程要先获得多种临界资源后才能执行的时候，则当所有临界资源都具备了才给进程分配，否则，一种都不分配。

管程的组成：
局部于管程内部的共享数据结构说明
对该数据结构进行操作的一组过程
对局部于管程内部的共享数据设置初始值的语句

管程将共享资源和对他进行的操作的若干过程围了起来
所有进程要访问临界资源时，都必须经过管程(相当于通过围墙的门)才能进入，而管程每次只准许一个进程进入管程
从而实现进程的互斥

管程是一种程序设计语言结构成分，他和信号量有同等的表达能力，从语言角度看吧，管程有如下特征：
将所有临界资源都管理起来形成了管程，凡是对临界资源的访问都需要管程来实现同步。
管程的好处：解决了共享变量及信号量变量操作分布在各个进程中，产生的易读性差，可维护性差，正确性难保问题

模块化　管程是一个基本程序单位，可以单独编译
抽象数据类型，管程中不仅有数据，而且有对数据的操作
信息掩蔽：管程中的数据结构只能被管程中的过程访问，这些过程也是在管程内部定义的，供管程外的进程调用
而管程中的数据结构以及过程的具体实现外部不可见

管程和进程的不同：
虽然二者都定义了数据结构，单进程定义的是私有数据结构PCB，管程定义的是公有数据结构，比如消息队列
二者都存在对各自的数据结构上的操作，但是进程是有顺序程序执行有关的操作，而管程主要是进行同步操作和初始化序列操作
设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使用问题
设置进程和管程不同
简单的说：
系统管理数据结构
进程：PCB
管程：等待队列
管程被进程调用
管程操作是操作系统的固有成分，无创建和撤销
进程通过调用管程中的过程对共享数据结构实行操作，该过程就如通常的子程序一样被调用，因而管程为被动工作方式
进程则为主动工作方式

进程之间能并发执行，而管程则不能与调用者并发

进程具有动态性，由创建而诞生，由撤销而消亡，而管程则是操作系统中的一个资源管理模块，供进程调用

哲学家就餐问题：
问题描述：
当哲学家饥饿的时候，会先去拿他左边的筷子，即执行wait(choptick[i]);成功后，再去拿右边的筷子
执行chopstick[(i+1)%5]又成功后便可进餐，进餐完成后，优先放下左边的筷子。假如五个哲学家同饥饿的话，各自拿左边的裤子，都将引起无筷子可拿
而无限其等待，对于这样的问题，可采用下面解决方法：
至多允许有四位哲学家同时去拿最左边的筷子，最终能保证至少以为哲学家能够进餐，并在用完筷子后，呢过释放所有用过的两只筷子
从而使更多的哲学家能就餐

仅当哲学家的左右两只筷子均可用的时候，才允许他们拿起筷子进餐

规定奇数号的哲学家先拿起他左边的筷子，最后再拿去右边的筷子，而偶数号哲学家则相反

进程通信：
共享存储系统
消息传递系统
管道通信
管道：指用于链接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe

线程的定义：
进程内的一个执行单元和可调用实体
线程只拥有一点在运行中必不可省的资源（程序计数器、一组寄存器和栈），但他可与同属一个进程的其他线程
共享进程拥有的全部资源
在具有多线程的操作系统中，处理机调度的基本单位是线程，一个进程可以有多个线程，而且至少有一个可执行线程
线程和进程的区别：
进程是可拥有资源的独立单位
进程同时又是一个可独立调度和分派的单位，从而也就构成了进程并发执行的基础

创建进程、撤销进程、进程切换

调度性：
在引入线程的操作系统中，将线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，传统的两个属性被分开
使线程基本不拥有资源，这样系统的并发程度就会提高。在同一个进程中，线程的切换不会引起进程的切换，但从一个
进程中的线程切换到另一个进程中的线程的时候，将会引起进程的切换


并发性：
再引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可以并发执行，使得操作系统
具有良好的并发性，从而有效的提高系统的资源利用率和吞吐量

拥有资源：
不论是传统的操作系统，还是引入了线程操作系统，进程都可以拥有资源，是系统中拥有资源的一个基本单位
一般而言线程自己不拥有资源，但他可以访问其隶属的进程的资源。

系统开销：

在创建进程的时候，系统都要为之创建和回收进程和控制块，分配或者回收资源。
在内存空间和IO设备，操作系统所付出的开销明显大于线程创建或撤销的开销，类似的，在进程切换的时候，涉及到当前进程的
切换则仅需保存和设置少量寄存器内容，不涉及存储器管理方面的操作。所以就切换代价而言，进程远高于线程。此外，一个进程中的
多个线程具有相同的地址空间，再同步和通信的实现方面线程比进程跟容易。

线程的属性：
轻型实体，基本不拥有资源
独立调度和分派的基本单位
可并发执行
共享进程资源

线程的状态：
状态参数通常有这几项：
寄存器状态、堆栈、线程运行状态、优先级、线程专有存储器、信号屏蔽

线程运行状态：
执行、就绪、阻塞

线程的创建和终止：
线程有自己的生命期，终止线程的方式有两种：一种是在线程完成了自己的工作后自愿退出，另一种是线程在运行中出现错误
或者由于某种原因而被其他线程强行终止。但有些线程，一旦被创建，便一直被运行，不会终止，当进程中的其他线程执行了分离函数后，
被终止线程才与资源分离，此时的资源才能被其他线程利用

、阻塞

线程的创建和终止：
线程有自己的生命期，终止线程的方式有两种：一种是在线程完成了自己的工作后自愿退出，另一种是线程在运行中出现错误
或者由于某种原因而被其他线程强行终止。但有些线程，一旦被创建，便一直被运行，不会终止，当进程中的其他线程执行了分离函数后，
被终止线程才与资源分离，此时的资源才能被其他线程利用

第三章
进程调度
作业：在批处理系统中，是以作业为基本单位从外存调入内存的
作业步
作业流
进程调度的三个原则：
排队器
分排器
上下文切换机制

进程调度方式
非抢占方式：
抢占方式：优先权原则，短作业原则，时间片原则

选择调度方式和调度算法的若干准则
面向用户的准则

周转时间短
响应时间快
截止时间的保证
优先权准则


面向系统的准则
系统吞吐量
处理机利用率好
各类资源的平衡利用

调度算法：
先来先服务
短作业优先调度算法

优先权调度算法的类型：
非抢占式优先权算法

抢占式优先权调度算法：
静态优先权：在创建进程时确定的，在进程的整个运行期间保持不变。
确定进程优先权的依据有如下三个方面：
进程类型
进程对资源的需求
用户要求
动态优先权
在创建进程的时候赋予优先权，是可以随进程的推进或者随等待时间的增加而改变的，以便获得
更好的调度性能。

周转时间：作业从提交到完成所经历的时间（批处理系统）
平均周转时间：T=1/n\*Ti(n\>i>=1)，平均带权周转时间：1/n\*(Ti/Tsi)（Tsi是实际运行时间）
响应时间：用户输入一个请求到系统给出首次响应的时间---分时系统
截止时间：开始截止时间和完成截止时间----实时系统，与周转时间有些类似
公平性：不因工作或进程本身的特性而使上述指标过分恶化

先来先服务FCFS(先进先出调度算法FIFO)
按照进程进入就绪队列的先后次序，分派CPU
当前进程占用CPU，知道执行完或者阻塞，才让出CPU
在进程唤醒后，并不立即恢复执行，通常等到当前进程让出COU

特点：比较利于长作业，不利于短作业
有利于CPU繁忙的作业，而不利于IO繁忙的作业

短作业优先调度算法
选择就绪队列中估计事件最短的进程投入运行。通常后来的短作业不抢占正在执行的作业
优点：比FCFS改善的平均周转时间和平均带权时间，缩短了作业的等待时间

提高系统吞吐量

对长作业不利，可能长时间得不到执行
未能依据作业的紧迫程度来划分执行的优先级
难以准确估计作业的执行时间，从而影响调度性能

优先调度算法
优先选择就绪队列中优先级最该的进程投入运行，分为：
非抢占式优先级算法：仅发生在进程放弃CPU
抢占式：可剥夺当前运行进程CPU

高响应比优先调度算法(HRRF)
HRRF 是FCFS和SJF的折衷算法，响应比R用下式动态计算：
响应比R =(等待时间+要求服务时间)/要求服务时间

时间片轮转算法
通过时间片轮转，提高进程并发性和响应时间特性，从而提高资源利用率

多级反馈队列算法（多队列论转法）
思想：通过多个就绪队，分别赋予不同的优先级，队列1的优先级最高，其他逐级降低
每队列分配不同的时间片，规定优先级越低，则时间片越长

进程就绪后，先投入队列１的末尾，按FCFS算法调度。若一个事件片未能执行完，则降低
投入到队列２的末尾，一次类推，降低最后的队列，则按照时间片轮转算法调度直到完成
进程由于等待事件而放弃CPU，进入等待队列，一旦事件发生，则回到原来就绪队列
仅当较高优先级的队列为空，才调度较低优先级队列中的进程执行，如果进程执行有新进程
进入较高优先级的队列，则抢占执行新进程，并把被抢占的进程投入原队列的末尾

IO型进程：让其进入最高优先级队列，以及时相应IO交互，执行一个时间片，要求可处理完一次IO请求的数据然后转入阻塞队列

计算型进程：每次执行完时间片，进入更低优先级队列。最终采用最大时间片来执行，减少调度次数

IO次数不多，而主要是CPU处理的进程，在IO完成后，返回原先Io请求时的离开的队列，以免都回到最高优先级队列就再逐次下降


关于死锁的概念
死锁：指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态的时候，若无外力能力作用，他将无法推进。
产生死锁的原因：
竞争资源
进程推进顺序非法

产生死锁的必要条件
互斥条件：指进程对所分配的资源进行排他性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其他进程请求资源，则请求者只能等待，直到占有该资源的进程资源的进程用完释放
请求和保持：指进程已经保持了至少一个资源，但又提出新的资源请求，而该资源已经被其他进程占用，此时请求进程阻塞。
不可剥夺条件：指进程已经获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
环路等待：只在发生死锁的时候，必然存在一个进程，资源的环形链，即进程集合中的p0正在等待一个P1占用的资源；P1正在等待P2占用的资源......
处理死锁的基本方法

预防死锁，避免死锁，检测死锁，解除死锁

预防死锁的方法：
摒弃请求与保持条件
在资源分配的时候，只要有一种资源不满足要求，尽管其他所需的资源都是空闲的，则还是不会将资源分配给该进程，知道所有资源都满足请求的
条件，才进行分配
摒弃不剥夺条件：在一个已经请求可系统资源的进程中，再次请求的某一个资源不能立刻满足条件的话，必须释放他已经保持的所有资源，待以后
需要时重新申请。这也意味着进程中有些已经占有的资源，在运行过程中被暂时释放掉，也可以认为被剥夺了，从而摒弃了不剥夺条件

摒弃环路等待条件：
系统将所有的资源进行线性排队，并赋予不同的序号。所有进程对资源的请求必须按照资源序号递增次序提出，这样在所形成的资源分配图中不可能在出现环路

死锁的检测手段：保存一些资源请求和分配的信息；
提供一种算法，以利用这些信息来检测是否进入死锁
资源分配图

死锁的解除：
剥夺资源
撤销进程

第四章　存储器层次结构
存储器管理

计算机最基本的存储结构：寄存器，主内存，辅存
主存储器作为计算机系统中的一个主要部件，用于保存进程运行时的程序和数据，数据能够从主存中读取并装入到寄存器中，或者从寄存器存入到存储器中

寄存器和高速缓存是解决CPU和主存之间数据访问速度不匹配的问题的

寄存器
访问速度最快，完全能和CPU进行协调工作。容量小，长度以字为单位

高速缓存速度高于主存储器，容量为几十KB到几MB，访问速度要快于主存储器

根据程序执行的局部性原理，将主存中一些经常访问的信息存放在高速缓存中，减少访问主存的次数，提高程序执行速度

程序的装入与链接
再多道程序环境下，要程序运行，必须先为之创建进程，而创建进程的第一件事，就是将程序和数据装入到内存。

常见的装入方式：
绝对装入方式
按照装入模块的地址将程序按照装入模块的地址，将程序和数据装入到内存，装入模块被装入到内存后，由于程序的中的逻辑地址
和实际地址完全相同，故不需要对程序和数据的地址进行修改。
绝对装入方式只能将目标模块装入到内存中实现指定的位置。适合于单道程序环境

可重定位装入方式
可重定位装入方式可将装入模块装入到内存中的任何位置，用于多道程序环境；但这种
方式不允许在程序运行的时候在内存中移动位置。程序在内存中的移动，意味着他在物理
位置发生变化，这时必须对程序和数据的地址进行修改后，方能运行。

动态运行时装入方式

程序的链接

程序在经过编译后，得到一组目标模块，再利用链接程序将这组目标模块链接，形成装入模块
静态链接:
对相对寻址进行修改。在链接成一个装入模块后，原模块B和C在装入模块的起始地址不在是0，而分别是L和L+M，所以此时
修改模块B和C中的相对地址，即将原来B中相对地址加上L，把原来C中的所有相对地址加上L+M
变换外部调用符号
将每个模块所用到的外部调用符号也都变换成相对地址，如把B的起始地址变换成L，将C的起始地址变换成L+M
装入时动态链接:
便于修改和更新
便于实现对目标模块的共享
运行时动态链接
在程序运行的时候，需要用到那些模块，就将相应的模块装到内存，节省了动态装入时占用的大量空间

内存分配算法：
首次适应算法
循环首次适应算法
最佳适应算法
最坏适应算法
快速适应算法

伙伴系统规定：

假设系统的可用空间容量是2的m次方个字，则系统开始运行时，整个内存区是一个大小为2的m次方的
空闲分区。在整个系统运行过程中，由于不断的划分，可能形成若干个不连续的空闲分区，将这些
空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区链表，
这样，不同大小的空闲分区形成了k个空闲分区链表

当需要为进程分配一个长度为n的存储空间的时候，首先计算一个i值，使2^(i-1)<n>=2^i，然后
在空闲分区大小为2^i的空闲分区链表中查找，若找到，就将该空闲分区分配给进程，否则，表明
长度为2^i的空闲分区已经耗尽，则在空闲分区大小为2^(i+1)的空闲链表中寻找，若存在2^(i+1)的一个
空闲分区，就将该空闲分区分成相等的两个2^i大小的分区，整两个分区称为一对伙伴，其中一个分区专门用来
分配，另一个将被加到2^i中的空闲链表中。若大小为2^(i+1)的分区不存在，查找2^(i+2)的空闲分区，若找到
进行两次分割，第一次，将其分割成大小为2^(i+1)的大小的两个分区，一个用于分配，一个用于加到2^(i+1)的空闲分区
链表中，第二次，将第一次用于分配的空闲分区分割成2^i的两个分区，一个用于分配，一个加到2^i空闲分区链表中，若仍然找不到，
继续查找有大小为2^(i+3)的大小的空闲分区，以此类推

与一次分配可能已进行多次分割，一次回收可能要进行多次合并，回收2^i的空闲分区时，若事先已经存在2^i的空闲分区，则应该
将其与伙伴合并为大小为2^(i+1)的空闲分区，若事先已经存在2^(i+1)的空闲分区，又应继续与其伙伴分区合并为大小为2^(i+2)的空闲分区

哈希算法
对于每一类具有相同
大小的空闲分区，单独设立一个空闲分区链表，在为进程分配空间时，需要在一张管理索引表中查找所需空间大小对应的表项，从中找到对应的空闲
分区链表表头指针，从而通过查找得到一个空闲分区。如果对空闲分区分类较细，则相应的空闲分区链表也较多，因此选择合适的空闲链表的开销相应增加，时间性能降低


可重定位分区分配

动态重定位

动态重定位分配算法：
动态重定位分配算法与动态分区分配算法基本上相同，差别在于：这种算法中增加了紧凑的功能，通常在找不到空闲分区
满足不了用户需求的情况下，进行紧凑

对换
为了解决大进程占用内存的情况下，导致其他进程没法运行，导致CPU停止下来等待的情况

兑换空间的管理：
在具有兑换功能的OS中，将外存分成对换区和文件区
前者用于存放从内存中换出的进程，后者用于存放文件

进程的换出：每当进程由于创建子进程需要更多内存空间

分段存储管理方式的引入：
方便编程
信息共享
信息保护
动态增长
动态链接

分页和分段的区别：
页是信息的物理单位，分页实现离散分配方式，消减内存的外零头，提高内存利用率
。或者说，分页仅仅是因为系统管理的需要，而不是用户的需要，段则是逻辑单位，它含有一组
其意义相对完整的信息，分段的目的是为了更好的满足用户的需要。

页的大小确定并且有系统决定，由系统将逻辑地址划分成页号和页内地址两部分，是由机器
硬件实现的，因而在系统中只能有一种大小的页面，段的长度是不固定的，决定用户编写的程序，
通常由编译程序对源程序进行编译时，根据信息划分

分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需要利用一个记忆符，就能表示
一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址空间时，即需要会给出段名，
有需要给出段内地址

信息共享
分段的一个突出优点是信息共享，是易于实现段的共享，即允许若干个进程共享同一分段，且对段的保护也十分简单易行。在
分页系统中，虽然也能实现程序和数据的共享，但远不如分段方便：在一个多用户系统，可同时接纳40个用户，他们执行一个文本编辑程序，
如果文本编辑程序有160kb的代码和另外40kb的数据，则共需要8MB的内存空间来支持40个用户。如果
160kb的代码是可重入的，则无论实在分页还是分段系统中，该代码都能被共享。在内存中只需要保留一份文本编辑程序的副本，此时需要的内存空间
仅为1760kb，假定，每个页面的大小为4kb，那么160kb将占40个页面，应在每个进程的页表中建立40个页面，数据区占10个页面，为实现代码的共享，
还需要在每个进程的页表中，建立40个页表项。
在分段系统中，实现共享则很容易，只需要在每个进程的段表中为文本编辑程序设置一个段表项

可重入代码称为纯代码，是一种允许多个进程同时访问的代码。在多进程共享同一段代码的时候，不允许可重入代码有任何改变

段页式存储管理
是分段和分页原理的结合，即先将用户程序分成若干段，再将每个段分成若干页面，并为每一个段赋予一个段名。

段号　段内页号　页内地址

在段页式系统中，为了方便实现地址变换，需要配置一个段寄存器，其中存放段表始址和段表长度。进行地址变换的时候，
首先利用段号S，将它与段表长TL进行比较，若S<TL，表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置
从中得到该段的页表地址，并利用逻辑地址中的段内页号P来获取对应页的页表项位置，从中读出该页所在物理块号b，再利用快号b和页内地址来构成物理地址


虚拟存储的基本概念

有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部装入内存，致使作业无法运行
有大量作业要求运行，但是由于内存容量不足以容纳所有这些作业，只能将少数作业装入到内存让他们先运行，而将其它大量作业留在外存等待

虚拟内存特征:
局部性原理：在一段时间内，程序的执行仅限于某一部分：相应的，他所访问的存储空间也局限于
某个区域
在执行的时候，除了少数的转移或过程调用指令外，大多数指令是顺序执行的
过程调用将会使程序的执行轨迹由一部分区域转换至另一部分区域，但经研究看出，过程调用的深度在大多数
情况下都不超过5，也就是说程序会在一段时间内都局限在这些过程的范围内运行
程序中存在许多循环结构，这些虽然只由少数指令构成，但是他们将多次执行
......
局限性
时间局限性和空间局限性

虚拟存储器的实现：
分页请求系统
硬件支持：
请求分页的页表机制
缺页中断机构
地址转换机构
软件支持：
请求分段的段表机制
缺段中断机构
地址变换机构

虚拟存储器的特征：
多次性
对换性
虚拟性

请求分页存储管理方式
页表机制
其中每个页表项包含页号、物理块号，状态位，访问字段、修改位、外存地址
缺页中断机构
在指令执行期间产生和处理中断信号
一条指令在执行期间可能产生多次缺页中断

地址变换机构

内存分配策略和分配算法
第一，最小物理块数的确定；
指能保证进程正常运行所需的最小物理块数，进程应该会获取的物理块数和计算机硬件结构相关，
取决于指令的格式，功能和寻址方式。对于某些简单的机器，若是单地址指令且采用直接寻址，所需要的物理块数最少为2。其中一块
是用于存放指令的页面，另一块则是用于存放数据的页面。机器允许间接寻址时，则至少需要三个物理块，对于某些较强的机器，其指令长度可能是
两个或多余两个字节，因而其指令本身也可能跨多个页面原地址和目标地址也可能跨多个页面。
第二，物理块的分配策略；
固定分配局部置换
指基于该进程的类型，或者根据程序员建议为每个进程分配一定数目的物理块，在整个运行期间都不会改变
可变分配全局置换
这可能是最易于实现的一种物理分配和置换策略，以用于若干个OS中，在采用这种策略时，先为系统中的每个进程分配一定数目的
物理块，而OS自身也保持一个空闲物理块队列
可变分配局部置换
为每个进程分配一定数目的物理块，但当某进程发现缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其他进程的运行。这样不会影响其它进程
第三，物理块的分配算法
平均分配算法
将系统中所有可分配的物理块平均分配给各个进程。
按比例分配算法
根据进程的大小按照比例分配物理块的算法
考虑优先权的分配算法

调页策略
调入页面的时机
预调页策略：在进程首次调入的时候，由程序员决定调入那些页
请求调页策略

确定从何处调入页面？
请求分页的外存分为两部分：用于存放文件区和用于存放兑换页面的对换区。
兑换区采用连续内存分配方式，文件区采用离散内存分配方式，故兑换区的磁盘IO比文件区的高。
这样，每当发生缺页请求时，系统应从何处将缺页调入内存：
（１）系统拥有足够的内存空间，这时可以全部从对换区调入到所需页面，以提高速度。
（２）缺少足够的对换区空间，这时凡是不会被修改的文件都直接从文件区调入
（３）Unix方式，由于与进程有关的文件还放在文件区，故凡是未运行过的页面，都应该从文件区调入,对于曾经运行过但又被换出的页面，由于被放在对换区，因此早下一次调入的时候
应从对换区调入。

页面调入过程？
每当进程访问的页面未在内存中，便向CPU发出一缺页中断，中断处理程序首先保留CPU环境，分析中断原因后，转入缺页中断，中断处理程序保留CPU环境，
分析中断原因后，转入缺页中断处理程序。该程序通过查找页表，得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘IO将所缺的页面调入内存，
然后修改页表，如果内存已满，则需要先按照某种置换算法，从内存中选出一页准备换出，如果页未被修改，可不必将该页写回磁盘；但如果此页已被修改，则必须
将它写回磁盘，然后，把所缺的页面调入内存，并修改页表中的相应页表项，置其存在位为1，将此页表项写入快表中
在调入内存后，利用修改后的页表，去形成所要访问的页表，去形成所要访问数据的物理地址，再去访问内存数据。

页面置换算法
最佳页面置换算法
其选择的被淘汰页面将是以后不适用的，或是在最长未来时间不会再被访问的页面。采用最佳页面置换算法，通常保证最低的缺页率，该算法是比较理想的
，在十几种是没法实现的，所以可以利用他来做为衡量其他页面置换算法的标准

先进先出页面置换算法
首先被换入到内存的页面，也就是驻留在内存中最久的页面，在缺页的时候，会被新页面替代。该算法与进程实际运行的规律不相适应，因为在进程中，有些页面是经常访问的。

最近最久未使用置换算法
根据页面调入内存的后的使用情况进行决策，由于无法预测各页面将来的使用情况，只能利用“最近的过去”和“最近的将来”的近似，因此，LRU置换算法是选择最近最久未使用
的页面进行淘汰。该算法为每个页面赋予一个字段，用来记录上次被访问以来所经历的时间，必须淘汰页面的时候，选择现有页面中时间最长的进行换出

简单的clock置换算法（NRU）
需要为每个页面设置一个访问位，在将内存中的所有页面都通过链接指针连接成一个循环队列。当某一页被访问的时，则访问位置１，置换算法在选择一页淘汰时，只需检查页的访问位。如果是０，就选择该页换出，若果是1，将访问位置０，暂不换出，而给该页第二次驻留的机会，再按照FIFO算法检查下一个页面。当检查最后一个页面，若访问位是１
，则再返回到队首检查下一个页面。

改进型的clock置换算法
在讲一个页面换出道外存时，如果该页面已经被修改过，便需将该页重新写回磁盘，但如果未被修改，则不必将它考回磁盘，在改进型clock算法中，除需考虑页面的使用情况
，还需要增加一个因素，即置换代价，这样，选择页面换出时，要是未使用过的页面，又要是未被修改过的页面，把同时满足这两个条件的页面作为首选淘汰的页面。由访问位A和修改位M可以组合成下面四种类型的页面：

即未被访问，又未被修改　最佳淘汰页面
最近未被访问，但是已被修改　不是最好的淘汰页面
最近已经被访问，但未被修改　有可能再被访问
最近已被访问，并且被修改，该页可能再被访问

要多次扫描页表，找可置换页，但是减少了磁盘IO操作次数

其他页面置换算法
最少使用置换算法
页面缓冲算法

请求分段存储管理方式
硬件置换算法：存取方式、访问字段、修改位、存在位、增补位、外存始址

缺段中断机构
缺段中断等

分段的共享和保护

共享段表
共享进程计数

存取控制字段
段号

设备管理
按设备的使用特性分类：
存储设备
输入输出设备
交互式设备

按传输速率进行分类
低速设备
传输速率仅为每秒钟几个字节至几百个字节的一类设备
中速设备
高速设备
按信息交换的单位
字符设备
块设备

按照设备的共享属性分类：
独占设备
共享设备
虚拟设备

设备与控制器之间的接口
数据信号线，控制信号线，状态信号线

设备控制器：控制计算机中一个或者多个IO设备，实现IO设备与计算机之间的数据交换。他是CPU与IO设备之间的接口，他接收从
CPU发来的命令，并去控制IO设备工作，以使处理机从繁杂的设备控制事务中解脱出来

IO控制方式：
程序IO控制方式、中断驱动IO控制方式、DMA控制方式

DMA控制方式：数据传送的单位是数据块，即在CPU与IO设备之间，每次传送至少一个数据块
所传送的数据是从设备直接送入内存的，或者相反
仅在传送一个或者多个数据块的开始和结束时，才需要COU干预，整块数据的传送是在控制器的控制下完成的
DMA控制方式减少了CPU对IO的干预，进一步提高了CPU与IO设备的并行操作程度

DMA的工作过程：
当CPU要从磁盘读入一数据块时，便向磁盘控制器发送一条读指令
该指令被送到其中的命令寄存器(CR)中
同时，还需发送本次要将数据读入的内存起始目标地址(MAR)
本次要读数据的字节数则送入数据计数器(DC)中
还需将磁盘的源地址送到DMA控制器的IO控制逻辑上
然后启动DMA进行数据传送，以后CPU便可处理其他任务
整个数据传送过程便由DMA控制器进行控制
当DMA控制器已经读到一个字的数据，送到数据寄存器DR后，再挪用一个存储周期
将该字送到MAR所指示的内存单元中。接着，便对MAR内容加1，将DC内容减1。
若减1后DC内容不为0，表示传送未完，便继续传送下一个字节，否则，由DMA控制器发出中断请求。

IO通道控制方式
IO通道控制方式的引入
虽然DMA方式比起中断方式来已经显著减少了CPU的干预，即已由以字节为单位的干预转化成以数据块为单位的干预。但CPU发送一个IO指令，也只能读一个连续的数据块，
当我们想读多个数据块且将它们分别送到不同的内存区域中，或者相反的话，则需要CPU分别发出多条IO指令及进行多次处理

IO通道方式是DMA的发展，它可进一步减少CPU的干预，即将对一个数据块的干预减少到对一组数据块的读写及有关的控制
和管理为单位的干预。
提高了资源利用率

缓冲的引入：缓和CPU与IO设备之间速度不匹配的矛盾
减少对CPU的中断频率，放宽对CPU中断响应时间的限制
提高CPU与IO设备之间的并行性

单缓冲和双缓冲
循环缓冲
加快输入输出的速率，提高设备利用率

中断处理程序
中断处理层的主要工作：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。由于
中断处理程序与硬件紧密相关，对用户及用户程序而言，应尽量屏蔽，中断处理过程：

唤醒被阻塞的驱动程序
保护被中断进程的CPU环境
转入相应的设备设备处理程序
中断处理
恢复中断进程的现场

磁盘存储器的管理
数据的组织及格式：磁盘设备可包括亦或者多个物理盘片，每个磁盘片分一个或者两个存储面，每个磁盘面被组织成若干个同心环
这种环称为磁道，各磁道之间留有必要的间隙，为使简单处理，在每条磁道上可存储相同数目的二进制位。这样，磁盘密度即每英寸
中所存储的位数，显然是内层磁道的密度郊外层磁道的高。每条磁道又被划分成若干个扇区，软盘大约为8~32个扇区，硬盘可多达数百个
一个扇区被称为一个盘块，各扇区之间保留一定的间隙


文件管理
文件指有创建者定义的、具有文件名称的一组元素的集合，可分为有结构文件和无结构文件。
文件在文件系统中，由若干个相关记录组成，而无结构文件则被看成是一个字符流。文件在文件系统中是一个最大的数据单位，他描述了一个对象集
文件类型、文件长度、文件的物理位置、文件的建立时间
文件类型：系统文件、用户文件、库文件
按文件中的数据形式分类：源文件、目标文件、可执行文件
按组织形式和处理方式分类：普通文件（有ascll码和二进制码组成的字符文件）、目录文件（有文件目录组成）、特殊文件（特指各类IO设备）

文件系统模型
从上而下：用户程序－》对对象操作和管理的软件集合－》对象及属性
对象及其属性
文件管理系统管理的对象：
１.文件
他作为文件管理的直接对象　
２.目录 
为了方便用户对文件的存取和检索，在文件系统中必须配置目录，每个目录项中，必须含有文件名及该文件所在的物理
地址。对目录的组织和管理是方便用户和提高对文件存取速度的关键
3.磁盘存储空间
文件和目录必定占用存储空间，对这部分空间的有效管理，不仅能提高外存的利用率，而且能提高对文件的存取速度
对对象操作和管理的软件集合
这是文件管理系统的核心部分。文件系统的功能大多是在这一层实现的。其中包括对文件写存储空间的管理。对文件目录
的管理，用于将文件的逻辑地址转换成物理地址的机制，对文件读和写的管理，以及对文件的共享和保护等功能
文件系统的接口：
命令接口
程序接口

文件系统的内存分配方式
连续内存分配：要求每个文件分配一组相邻接的盘块，一组盘块的地址定义了磁盘上的一段线性地址。
优点：顺序访问容易。
顺序访问速度快
缺点：要求有连续的内存块。
必须事先知道文件的长度

链接分配：通过在每个盘块上的链接指针，将同一个文件的多个离散的盘块链接成一个链表，把这样形成的物理文件称为链接文件。
隐式分配：在文件目录的每个目录项中，都需含有指向链接文件第一个盘块和最后一个盘块的指针
只适合于顺序访问，对随机访问是极其低效的。
显式链接：将用于链接个物理块的指针，显示地存在同一张连接表中。这张连接表存在于内存中。在查找指定块的时候，现在内存中找到相应的物理块的地址
然后对磁盘进行访问。
因为分配给该文件的所有盘块号都放在该表中，故将该表称为文件分配表(FAT)

每个fat表项是12位，在fat表中最多允许有4096表项，如果采用以盘块作为基本分配单位，每个盘块的大小一般是512字节，那么，每个磁盘
分区的容量为2MB，同时，一个物理磁盘支持４个逻辑磁盘分区，所以相应的磁盘最大容量仅为8MB。所以引入了簇：

簇的基本概念：
为了适应磁盘不断增大的需要，进行盘快分配的时候，不以盘块而是以簇为基本单位，簇是一组连续扇区，在FAT中，他是作为一个虚拟扇区，簇的大小是
2n个盘块，在ms-dos中，簇的容量仅为一个扇区，两个扇区，...一个簇包含一个扇区时，最大容量是8MB，当一个簇包含两个扇区的时候，磁盘最大容量
可以达到16MB;当一个簇包含了八个扇区的时候，磁盘的最大容量便可达到64MB

索引分配
解决连续存储带来的问题：
不能支持高效的直接存取，要对一个较大的文件进行直接存取，需首先正在FAT中顺序地查找许多盘块号
FAT需占用较大的内存空间
事实上在打开某个文件的时候，由于一个文件的占用的盘块号是随机分布在FAT中，因而只有将整个FAT调入内存，才能保证
在FAT中找到一个文件的所有盘块号。当磁盘容量较大时，FAT可能要占用数兆字节以上的内存空间。

没有必要将整个FAT调入内存，将每个文件所对应的盘块号，集中地放在一起。索引分配方法就是集中这种想法所形成的一种分配方法
为每个文件分配一个索引块为每个文件分配一个索引块，再把分配给该文件的所有盘块号都记录在该索引快中，因而该索引块就是一个含有许多
盘块号的数组。

目录管理：
实现安明存取
提高对目录的检索速度
文件共享
允许文件重名

